{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp vision.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "> Models for computer vision tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "from efficientnet_pytorch.utils import Conv2dStaticSamePadding\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import timm\n",
    "from dl_pipeline.external import xresnet_ssa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GeM pooling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gem(x, p, eps=1e-6):\n",
    "    t = x.type()\n",
    "    x = x.float()\n",
    "    x = F.avg_pool2d(x.clamp(min=eps).pow(p.view(1,-1,1,1)), \n",
    "                     (x.size(-2), x.size(-1))).pow(1.0/p.view(1,-1,1,1))\n",
    "    x = x.type(t)\n",
    "    return x\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, nc=1, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(nc)*p)\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps) \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'\\\n",
    "        .format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "    \n",
    "#export\n",
    "class AdaptiveConcatPool2d_GeM(Module):\n",
    "    \"Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`\"\n",
    "    def __init__(self, size=None):\n",
    "        self.size = size or 1\n",
    "        self.ap = nn.AdaptiveAvgPool2d(self.size)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(self.size)\n",
    "        self.gem = GeM()\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x), self.gem(x)], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models with fastai head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MobileNetV2(Module):\n",
    "    def __init__(self, num_classes, head_ps=0.5, pretrained=True, in_channels=3, **kwargs):\n",
    "        body = torch.hub.load('pytorch/vision:v0.6.0', 'mobilenet_v2', pretrained=pretrained)\n",
    "        body = nn.Sequential(*children_and_parameters(body)[:-1])\n",
    "        num_features = 1280\n",
    "        model = nn.Sequential(body, create_head(num_features*2, num_classes, ps=head_ps))\n",
    "        if in_channels == 1:\n",
    "            out_ch =model[0][0][0][0].out_channels\n",
    "            k_sz = model[0][0][0][0].kernel_size\n",
    "            stride = model[0][0][0][0].stride\n",
    "            pad = model[0][0][0][0].padding\n",
    "            w = model[0][0][0][0].weight.data[:,0].unsqueeze(1)\n",
    "            model[0][0][0][0] = nn.Conv2d(1, out_ch, kernel_size=k_sz, stride=stride, padding=pad, bias=False)\n",
    "            model[0][0][0][0].weight.data = w\n",
    "        self.layers = model\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mnpinto/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetV2(10, in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNet_(Module):\n",
    "    arch=None\n",
    "    def __init__(self, num_classes, head_ps=0.5, pretrained=True, in_channels=3, **kwargs):\n",
    "        body = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_swsl')\n",
    "        body = nn.Sequential(*children_and_parameters(body)[:-2])\n",
    "        num_features = body[-1][-1].bn2.num_features\n",
    "        model = nn.Sequential(body, create_head(num_features*2, num_classes, ps=head_ps))\n",
    "        if in_channels == 1:\n",
    "            out_ch = model[0][0].out_channels\n",
    "            k_sz = model[0][0].kernel_size\n",
    "            stride = model[0][0].stride\n",
    "            pad = model[0][0].padding\n",
    "            w = model[0][0].weight.data[:,0].unsqueeze(1)\n",
    "            model[0][0] = nn.Conv2d(1, out_ch, kernel_size=k_sz, stride=stride, padding=pad, bias=False)\n",
    "            model[0][0].weight.data = w\n",
    "        self.layers = model\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class ResNet18_swsl(ResNet_):\n",
    "    arch='resnet18_swsl'\n",
    "\n",
    "class ResNet50_swsl(ResNet_):\n",
    "    arch='resnet50_swsl'\n",
    "\n",
    "class ResNet50_32x4d_swsl(ResNet_):\n",
    "    arch='resnext50_32x4d_swsl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mnpinto/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n",
      "Using cache found in /home/mnpinto/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n",
      "Using cache found in /home/mnpinto/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18_swsl(1000, in_channels=1)\n",
    "model = ResNet50_swsl(1000, in_channels=1)\n",
    "model = ResNet50_32x4d_swsl(1000, in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class xResNet_(Module):\n",
    "    arch=None\n",
    "    def __init__(self, num_classes, head_ps=0.8, pretrained=True, in_channels=3, **kwargs):\n",
    "        model = eval(f'xresnet_ssa.{self.arch}')(pretrained=pretrained)\n",
    "        model = nn.Sequential(*[*children_and_parameters(model)[:-2], \n",
    "                *children_and_parameters(create_head(2048*2, num_classes, ps=head_ps))])\n",
    "        if in_channels == 1:\n",
    "            w = model[0][0].weight.data[:,0].unsqueeze(1)\n",
    "            model[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), \n",
    "                                    padding=(1, 1), bias=False)\n",
    "            model[0][0].weight.data = w\n",
    "        self.layers = model\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "class xResNet50_ssa(xResNet_):\n",
    "    arch='xresnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xResNet50_ssa(100, in_channels=1, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNeSt_(Module):\n",
    "    arch=None\n",
    "    def __init__(self, num_classes, head_ps=0.8, pretrained=True, in_channels=3, **kwargs):\n",
    "        try:\n",
    "            model = torch.hub.load('zhanghang1989/ResNeSt', self.arch, pretrained=pretrained)\n",
    "        except:\n",
    "            torch.hub.list('zhanghang1989/ResNeSt', force_reload=True)\n",
    "            model = torch.hub.load('zhanghang1989/ResNeSt', self.arch, pretrained=pretrained)\n",
    "        model = nn.Sequential(*[*children_and_parameters(model)[:-2], \n",
    "                *children_and_parameters(create_head(2048*2, num_classes, ps=head_ps))])\n",
    "        if in_channels == 1:\n",
    "            w = model[0][0].weight.data[:,0].unsqueeze(1)\n",
    "            model[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), \n",
    "                                    padding=(1, 1), bias=False)\n",
    "            model[0][0].weight.data = w\n",
    "        self.layers = model\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "class ResNeSt50(ResNeSt_):\n",
    "    arch='resnest50'\n",
    "    \n",
    "class ResNeSt101(ResNeSt_):\n",
    "    arch='resnest101'\n",
    "    \n",
    "class ResNeSt200(ResNeSt_):\n",
    "    arch='resnest200'\n",
    "    \n",
    "class ResNeSt269(ResNeSt_):\n",
    "    arch='resnest269'\n",
    "    \n",
    "class ResNeSt50_fast_1s1x64d(ResNeSt_):\n",
    "    arch='resnest50_fast_1s1x64d'\n",
    "\n",
    "class ResNeSt50_fast_1s2x40d(ResNeSt_):\n",
    "    arch='resnest50_fast_1s2x40d'\n",
    "    \n",
    "class ResNeSt50_fast_1s4x24d(ResNeSt_):\n",
    "    arch='resnest50_fast_1s4x24d'\n",
    "    \n",
    "class ResNeSt50_fast_2s1x64d(ResNeSt_):\n",
    "    arch='resnest50_fast_2s1x64d'\n",
    "    \n",
    "class ResNeSt50_fast_2s2x40d(ResNeSt_):\n",
    "    arch='resnest50_fast_2s2x40d'    \n",
    "\n",
    "class ResNeSt50_fast_4s1x64d(ResNeSt_):\n",
    "    arch='resnest50_fast_4s1x64d' \n",
    "\n",
    "class ResNeSt50_fast_4s2x40d(ResNeSt_):\n",
    "    arch='resnest50_fast_4s2x40d' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mnpinto/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    }
   ],
   "source": [
    "model = ResNeSt50(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DenseNet_(Module):\n",
    "    arch=None\n",
    "    def __init__(self, num_classes, head_ps=0.5, pretrained=True, in_channels=3, **kwargs):\n",
    "        body = eval(f'models.{self.arch}')(pretrained=pretrained).features\n",
    "        num_features = children_and_parameters(body)[-1].num_features\n",
    "        model = nn.Sequential(body, create_head(num_features*2, num_classes, ps=head_ps))\n",
    "        if in_channels == 1:\n",
    "            w = model[0].conv0.weight.data[:,0].unsqueeze(1)\n",
    "            model[0].conv0 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2,2), padding=(3, 3), bias=False)\n",
    "            model[0].conv0.weight.data = w\n",
    "        self.layers = model\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "class DenseNet121(DenseNet_):\n",
    "    arch='densenet121'\n",
    "    \n",
    "class DenseNet169(DenseNet_):\n",
    "    arch='densenet169'\n",
    "    \n",
    "class DenseNet201(DenseNet_):\n",
    "    arch='densenet201'\n",
    "    \n",
    "class DenseNet161(DenseNet_):\n",
    "    arch='densenet161'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet121(1000, in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DenseNetBlur121(Module):\n",
    "    arch='densenetblur121d'\n",
    "    def __init__(self, num_classes, head_ps=0.5, pretrained=True, in_channels=3, **kwargs):\n",
    "        body =  timm.create_model(self.arch,num_classes=num_classes, \n",
    "                                  pretrained=pretrained).features\n",
    "        num_features = body[-1].num_features\n",
    "        model = nn.Sequential(body, create_head(num_features*2, num_classes, ps=head_ps))\n",
    "        if in_channels == 1:\n",
    "            w = model[0].conv0.weight.data[:,0].unsqueeze(1)\n",
    "            model[0].conv0 = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "            model[0].conv0.weight.data = w\n",
    "        self.layers = model\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNetBlur121(24, in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class EfficientNet_(Module):\n",
    "    arch=None\n",
    "    def __init__(self, num_classes, head_ps=0.5, pretrained=True, in_channels=3, **kwargs):\n",
    "        self.effnet = EfficientNet.from_pretrained(self.arch)\n",
    "        if in_channels == 1:\n",
    "            w = self.effnet._conv_stem.weight.data[:,0].unsqueeze(1)\n",
    "            out_channels = self.effnet._conv_stem.out_channels\n",
    "            self.effnet._conv_stem = Conv2dStaticSamePadding(1, out_channels, kernel_size=(3,3), stride=(2,2), \n",
    "                                                             bias=False, image_size=(128,128))\n",
    "            self.effnet._conv_stem.weight.data = w\n",
    "        num_features = self.effnet._bn1.num_features\n",
    "        self.head = create_head(num_features*2, num_classes, ps=head_ps)\n",
    "    def forward(self, x):\n",
    "        x = self.effnet.extract_features(x)\n",
    "        return self.head(x)\n",
    "    \n",
    "class EfficientNetB0(EfficientNet_):\n",
    "    arch = 'efficientnet-b0'\n",
    "\n",
    "class EfficientNetB1(EfficientNet_):\n",
    "    arch = 'efficientnet-b1'\n",
    "    \n",
    "class EfficientNetB2(EfficientNet_):\n",
    "    arch = 'efficientnet-b2'\n",
    "    \n",
    "class EfficientNetB3(EfficientNet_):\n",
    "    arch = 'efficientnet-b3'\n",
    "    \n",
    "class EfficientNetB4(EfficientNet_):\n",
    "    arch = 'efficientnet-b4'\n",
    "\n",
    "class EfficientNetB5(EfficientNet_):\n",
    "    arch = 'efficientnet-b5'\n",
    "\n",
    "class EfficientNetB6(EfficientNet_):\n",
    "    arch = 'efficientnet-b6'\n",
    "    \n",
    "class EfficientNetB7(EfficientNet_):\n",
    "    arch = 'efficientnet-b7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNetB0(1000, in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, in_channels, emb_sz=128):\n",
    "        super().__init__()\n",
    "        self.flat = nn.Sequential(\n",
    "            AdaptiveConcatPool2d(1))\n",
    "        self.flatten = Flatten()\n",
    "        self.bn0 = nn.BatchNorm1d(in_channels)\n",
    "        self.lin0 = nn.Linear(in_channels, in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.lin1 = nn.Linear(in_channels, emb_sz)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.lin0(self.bn0(x)))\n",
    "        return self.lin1(self.bn1(x))\n",
    "    \n",
    "class EmbResNeSt_(Module):\n",
    "    arch=None\n",
    "    def __init__(self, emb_sz=128, head_ps=0.5, pretrained=True, **kwargs):\n",
    "        try:\n",
    "            model = torch.hub.load('zhanghang1989/ResNeSt', self.arch, pretrained=pretrained)\n",
    "        except:\n",
    "            torch.hub.list('zhanghang1989/ResNeSt', force_reload=True)\n",
    "            model = torch.hub.load('zhanghang1989/ResNeSt', self.arch, pretrained=pretrained)\n",
    "        model = nn.Sequential(*[*children_and_parameters(model)[:-2], \n",
    "                *children_and_parameters(Head(2048*2, emb_sz))])\n",
    "        w = model[0][0].weight.data[:,0].unsqueeze(1)\n",
    "        model[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), \n",
    "                                padding=(1, 1), bias=False)\n",
    "        model[0][0].weight.data = w\n",
    "        self.layers = model\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "class EmbResNeSt50(EmbResNeSt_):\n",
    "    arch='resnest50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mnpinto/.cache/torch/hub/zhanghang1989_ResNeSt_master\n"
     ]
    }
   ],
   "source": [
    "model = EmbResNeSt50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_model(arch, num_classes, head_ps=0.5, in_channels=3, pretrained=True,\n",
    "              device=torch.device(\"cuda:0\"), **kwargs):\n",
    "    if arch == 'resnest50':\n",
    "        return ResNeSt50(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                         in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'resnest101':\n",
    "        return ResNeSt101(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                           in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'densenet121':\n",
    "        return DenseNet121(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                            in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'densenet169':\n",
    "        return DenseNet169(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                            in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'densenet201':\n",
    "        return DenseNet201(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                            in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'densenet161':\n",
    "        return DenseNet161(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                            in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'densenetblur121d':\n",
    "        return DenseNetBlur121(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                            in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'efficientnetb0':\n",
    "        return EfficientNetB0(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                               in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'efficientnetb1':\n",
    "        return EfficientNetB1(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                               in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'efficientnetb2':\n",
    "        return EfficientNetB2(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                               in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'efficientnetb3':\n",
    "        return EfficientNetB3(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                               in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'efficientnetb4':\n",
    "        return EfficientNetB4(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                               in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'efficientnetb5':\n",
    "        return EfficientNetB5(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                               in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'efficientnetb6':\n",
    "        return EfficientNetB6(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                               in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'efficientnetb7':\n",
    "        return EfficientNetB7(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                               in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'resnet50_32x4d_swsl':\n",
    "        return ResNet50_32x4d_swsl(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                               in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'mobilenetv2':\n",
    "        return MobileNetV2(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                            in_channels=in_channels, **kwargs).to(device)\n",
    "    if arch == 'embresnest50':\n",
    "        return EmbResNeSt50(num_classes=num_classes, head_ps=head_ps, pretrained=pretrained,\n",
    "                            in_channels=in_channels, **kwargs).to(device)\n",
    "    raise Exception(f'{arch} not defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 00vision_losses.ipynb.\n",
      "Converted 00vision_models.ipynb.\n",
      "Converted 00vision_triplet.ipynb.\n",
      "Converted 01audio_augmentations.ipynb.\n",
      "Converted 01audio_core.ipynb.\n",
      "Converted 01audio_dataset.ipynb.\n",
      "Converted 01audio_util.ipynb.\n",
      "Converted 88_external_xresnet_ssa.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted kaggle_rfcx-species-audio-detection-sed.ipynb.\n",
      "Converted kaggle_rfcx-species-audio-detection.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (banet_dev)",
   "language": "python",
   "name": "banet_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
