{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp kaggle.rfcx_species_audio_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle rfcx-species-audio-detection competition\n",
    "\n",
    "> This module contains the pipeline for the rfcx-species-audio-detection competition: https://www.kaggle.com/c/rfcx-species-audio-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from fastprogress import progress_bar\n",
    "from IPython.core.debugger import set_trace\n",
    "import gc\n",
    "from fastscript import *\n",
    "from fastcore.all import *\n",
    "from fastai.vision.all import *\n",
    "from dl_pipeline.core import *\n",
    "from dl_pipeline.audio.core import *\n",
    "from dl_pipeline.audio.augmentations import *\n",
    "from dl_pipeline.audio.dataset import *\n",
    "from dl_pipeline.vision.models import *\n",
    "from dl_pipeline.vision.losses import *\n",
    "from dl_pipeline.audio.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def audio_augment(sample_rate, p=0.25):\n",
    "    return Pipeline([\n",
    "        ClippingDistortion(sample_rate, max_percentile_threshold=10, p=p),\n",
    "        PitchShift(sample_rate, min_semitones=-8, max_semitones=8, p=p),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train(sample_rate, num_classes, fold, n_epochs, lr, wd, tile_width, bs, aug_ps, \n",
    "          model_name, loss_func, plot, load_checkpoint=None, lr_find=False, head_ps=0.8,\n",
    "          mixup=False, n_mels=128, hop_length=512, model='resnest50'):\n",
    "    seed_everything()\n",
    "    cbs = []\n",
    "    path = Path('/kaggle/kaggle_rainforest_audio/data')\n",
    "    rename_cols = RenameColumns(id='recording_id', label='species_id', tmin='t_min', \n",
    "                                tmax='t_max',fmin='f_min', fmax='f_max')\n",
    "    \n",
    "    df = Pipeline([load_dataframe, rename_cols, group_labels])(path/'train_tp.csv')\n",
    "        \n",
    "    train_df, valid_df = kfold_dataframes(df, fold)\n",
    "        \n",
    "    tfms = partial(apply_augmentations, augs_pipeline=audio_augment(sample_rate, p=aug_ps))\n",
    "\n",
    "    train_data = Datasets(items=train_df, tfms=partial(create_dataset_item, path=path,\n",
    "                                               sample_rate=sample_rate, tile_width=tile_width,\n",
    "                                               n_mels=n_mels, hop_length=hop_length))\n",
    "    \n",
    "    valid_data = Datasets(items=valid_df, tfms=partial(create_dataset_item, path=path,\n",
    "                                               sample_rate=sample_rate, tile_width=tile_width,\n",
    "                                               n_mels=n_mels, hop_length=hop_length))\n",
    "    train_dl = DataLoader(\n",
    "        train_data, bs=bs, do_batch=reorganize_batch, shuffle=True, \n",
    "        num_workers=8, after_item=tfms, \n",
    "        after_batch=MelSpectrogram(sample_rate,n_mels=n_mels,hop_length=hop_length))\n",
    "    \n",
    "    valid_dl = DataLoader(\n",
    "        valid_data, bs=bs, do_batch=reorganize_batch, num_workers=8,\n",
    "        after_batch=MelSpectrogram(sample_rate, n_mels=n_mels,hop_length=hop_length))\n",
    "    \n",
    "    dls = DataLoaders(train_dl, valid_dl)\n",
    "    dls.device = torch.device(\"cuda:0\")        \n",
    "    \n",
    "    if plot: \n",
    "        xb, yb = dls.one_batch()\n",
    "        show_augmentations(train_data, train_dl, sample_rate=sample_rate)\n",
    "\n",
    "    model = get_model(model, num_classes=num_classes, head_ps=head_ps, in_channels=1)\n",
    "    \n",
    "    if mixup: \n",
    "        cbs.append(MixUp(0.4))\n",
    "        loss_func += '_mixup'\n",
    "    \n",
    "    def before_loss(x,y):\n",
    "        x,y=mask2category(x,y)\n",
    "        return x, y\n",
    "    \n",
    "    def after_loss(loss, y):\n",
    "        return loss\n",
    "    \n",
    "    loss = get_loss(loss_func, before=before_loss, after=after_loss)\n",
    "    print('Loss function: ', loss_func)\n",
    "            \n",
    "    learn = Learner(dls, model, loss_func=loss, metrics=[accuracy, lrap], cbs=cbs)\n",
    "    learn.to_fp16(clip=0.5);\n",
    "        \n",
    "    if load_checkpoint is not None:\n",
    "        learn.load(path.parent/f'models/{load_checkpoint}_fold{fold}')\n",
    "        print('Load model ', path.parent/f'models/{load_checkpoint}_fold{fold}')\n",
    "        \n",
    "    if lr_find: learn.lr_find()\n",
    "\n",
    "    learn.fit_one_cycle(n_epochs, lr, wd=wd, div_final=10, div=10)\n",
    "    learn.save(path.parent/f'models/{model_name}_fold{fold}')\n",
    "    print(f'Model saved to', path.parent/f'models/{model_name}_fold{fold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_preds(dataloader, model, device=torch.device(\"cuda:0\"), max_reduce=True):\n",
    "    model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "        preds, ys = [], []\n",
    "        for x, y in progress_bar(dataloader):\n",
    "            if max_reduce:\n",
    "                pred = model(x).max(0).values[None]\n",
    "            else:\n",
    "                pred = model(x)[None]\n",
    "            preds.append(pred.cpu())\n",
    "            ys.append(y.cpu())\n",
    "        preds = torch.cat(preds, dim=0)\n",
    "        ys = torch.cat(ys, dim=0)\n",
    "    return preds, ys\n",
    "        \n",
    "def test(sample_rate, num_classes, tile_width, model_name, ens_folds, head_ps=0.8, \n",
    "         n_mels=128, hop_length=512, save_preds=False, model='resnest50'):\n",
    "    bs = 1\n",
    "    _path_save = Path('preds')\n",
    "    _path_save.mkdir(exist_ok=True)\n",
    "    max_reduce = not save_preds\n",
    "\n",
    "    preds_ens, preds_valid, ys_valid = [], [], []\n",
    "    preds_train, ys_train = [], []\n",
    "    for fold in ens_folds:\n",
    "        seed_everything()\n",
    "        path = Path('/kaggle/kaggle_rainforest_audio/data')\n",
    "        rename_cols_test = RenameColumns(id='recording_id')\n",
    "        rename_cols_valid = RenameColumns(id='recording_id', label='species_id', tmin='t_min', \n",
    "                                    tmax='t_max',fmin='f_min', fmax='f_max')\n",
    "       \n",
    "        df = Pipeline([load_dataframe, rename_cols_valid, group_labels])(path/'train_tp.csv')\n",
    "       \n",
    "        train_df, valid_df = kfold_dataframes(df, fold)\n",
    "        \n",
    "        test_df = Pipeline([load_dataframe, rename_cols_test])(path/'sample_submission.csv')\n",
    "        fp_df = Pipeline([load_dataframe, rename_cols_valid, group_labels])(path/'train_fp.csv')\n",
    "\n",
    "        datasets = [Datasets(items=dataframe, tfms=partial(create_dataset_item, path=path,\n",
    "            sample_rate=sample_rate, tile_width=None, n_mels=n_mels, hop_length=hop_length))\n",
    "            for dataframe in [train_df, valid_df, test_df, fp_df]]\n",
    "        \n",
    "        dls = DataLoaders(*[DataLoader(dataset, bs=bs, do_batch=reorganize_batch, num_workers=8, \n",
    "                        after_batch=Pipeline([MelSpectrogram(sample_rate, n_mels=n_mels, \n",
    "                                    hop_length=hop_length), TilesTransform(tile_width)])) \n",
    "             for dataset in datasets])\n",
    "        \n",
    "        model = get_model(model, num_classes=num_classes, head_ps=head_ps, in_channels=1,\n",
    "                          pretrained=False)\n",
    "\n",
    "        dls.device = torch.device(\"cuda:0\")        \n",
    "        learn = Learner(dls, model, loss_func=cross_entropy, metrics=[accuracy, lrap])\n",
    "        learn.to_fp16(clip=0.5);\n",
    "        learn.load(path.parent/f'models/{model_name}_fold{fold}')\n",
    "        print('Load model: ', path.parent/f'models/{model_name}_fold{fold}')\n",
    "\n",
    "        preds, ys = get_preds(dls[1], model, max_reduce=max_reduce)\n",
    "        np.save(_path_save/f'{model_name}_{tile_width}_fold{fold}_valid.npy', \n",
    "                {'preds':preds, 'ys':ys})\n",
    "        if not max_reduce: preds = preds.max(1).values\n",
    "        preds_valid.append(preds)\n",
    "        ys_valid.append(ys)\n",
    "\n",
    "        preds, ys = get_preds(dls[2], model, max_reduce=max_reduce)\n",
    "        np.save(_path_save/f'{model_name}_{tile_width}_fold{fold}_test.npy', \n",
    "                {'preds':preds, 'ys':ys})\n",
    "        if not max_reduce: preds = preds.max(1).values\n",
    "        preds_ens.append(preds[None])\n",
    "        \n",
    "    preds_valid, ys_valid = torch.cat(preds_valid), torch.cat(ys_valid)\n",
    "    valid_score = lrap(preds_valid, ys_valid.long().squeeze(), before=lambda *o:o)\n",
    "    print(f'Validation score: {valid_score:.3f}')\n",
    "    \n",
    "    preds_ens = torch.cat(preds_ens).mean(0).softmax(-1)\n",
    "    test_df = Pipeline([load_dataframe])(path/'sample_submission.csv')\n",
    "\n",
    "    for i in range(preds_ens.shape[1]):\n",
    "        test_df.loc[:, f's{i}'] = preds_ens[:,i]\n",
    "\n",
    "    tstr = datetime.now().strftime('%Y%m%d%H%M')\n",
    "    test_df.to_csv(path.parent/f'subs/submission_{tstr}.csv', \n",
    "                   index=False)\n",
    "    print('Submission file saved: ', path.parent/f'subs/submission_{tstr}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def main(fold:Param('Fold number', int)=0, \n",
    "         n_epochs:Param('Number of training epochs', int)=30,\n",
    "         lr:Param('Learning rate', float)=1e-3,\n",
    "         wd:Param('Weight decay', float)=3e-2,\n",
    "         loss_func:Param('Loss function', str)='cross_entropy',\n",
    "         tile_width:Param('Tile width', int)=1024,\n",
    "         sample_rate:Param('Sample rate', int)=32000,\n",
    "         n_mels:Param('Spectrogram n_mels', int)=128,\n",
    "         hop_length:Param('Spectrogram hop_length', int)=640,\n",
    "         bs:Param('Batch size', int)=32,\n",
    "         accumulate_gradients:Param('Batch size for gradient accumulation', int)=None,\n",
    "         aug_ps:Param('Augmentation probability', float)=0.25,\n",
    "         model:Param('Name of model architecture', str)='densenet121',\n",
    "         model_name:Param('Name of parameters file', str)='model_n0',\n",
    "         ens_folds:Param('Folds to use for ensemble', list)=[0,1,2,3,4],\n",
    "         run_test:Param('Run test prediction (default is train)', str)=False,\n",
    "         load_checkpoint:Param('Load model checkpoint before new train loop', str)=None,\n",
    "         head_ps:Param('Model head dropout probability', float)=0.8,\n",
    "         mixup:Param('Use mixup', str)=True,\n",
    "         save_preds:Param('Save model predictions for train and validation', str)=False):\n",
    "    \n",
    "    num_classes = 24\n",
    "    if run_test in [True, 'true', 'True']: run_test = True\n",
    "    if mixup in [True, 'true', 'True']: mixup = True\n",
    "    if save_preds in [True, 'true', 'True']: save_preds=True\n",
    "    if run_test:\n",
    "        test(sample_rate, num_classes, tile_width, model_name, ens_folds, head_ps=head_ps, \n",
    "             n_mels=n_mels, hop_length=hop_length, save_preds=save_preds, model=model)\n",
    "    else:\n",
    "        train(sample_rate, num_classes, fold, n_epochs, lr, wd, tile_width, bs, aug_ps, \n",
    "          model_name, loss_func, plot=False, load_checkpoint=load_checkpoint, lr_find=False,\n",
    "          head_ps=head_ps, mixup=mixup, n_mels=n_mels, hop_length=hop_length, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Train model\n",
    "```python\n",
    "for i in [0,1,2,3,4]:\n",
    "    train(\n",
    "        sample_rate=32000,\n",
    "        num_classes=24,\n",
    "        fold=i,\n",
    "        n_epochs=30,\n",
    "        lr=1e-3,\n",
    "        wd=3e-2,\n",
    "        n_mels=128,\n",
    "        hop_length=640,\n",
    "        tile_width=1024,\n",
    "        bs=32,\n",
    "        aug_ps=0.25,\n",
    "        model='densenet121',\n",
    "        model_name='model_n68',\n",
    "        loss_func='cross_entropy', \n",
    "        plot=False,  \n",
    "        load_checkpoint=None, \n",
    "        lr_find=False, \n",
    "        head_ps=0.8,\n",
    "        mixup=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions\n",
    "```python\n",
    "for w in [64, 128, 256]:\n",
    "    test(sample_rate=32000, \n",
    "         num_classes=24, \n",
    "         n_mels=128,\n",
    "         hop_length=640,\n",
    "         tile_width=w, \n",
    "         model='densenet121',\n",
    "         model_name='model_n68', \n",
    "         ens_folds=[0,1,2,3,4],\n",
    "         save_preds=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running on terminal\n",
    "```bash\n",
    "#!/bin/bash\n",
    "arch='densenet121'\n",
    "model_name='model_n100'\n",
    "sample_rate=32000\n",
    "n_mels=128\n",
    "hop_length=640\n",
    "for fold in 0 1 2 3 4\n",
    "do\n",
    "    echo \"Training $model for fold $fold\"\n",
    "    kaggle_rainforest2021 --fold $fold --model_name $model_name --model $arch \\\n",
    "                          --sample_rate $sample_rate --n_mels $n_mels \\\n",
    "                          --hop_length $hop_length --bs 32 --head_ps 0.8 \\\n",
    "                          --tile_width 1024 --mixup true >> log.train\n",
    "done\n",
    "\n",
    "for tw in 64 128 256\n",
    "do\n",
    "    echo \"Generate predictions for $model with tile_width of $tw\"\n",
    "    kaggle_rainforest2021 --run_test true --model_name $model_name --model $arch \\\n",
    "                          --sample_rate $sample_rate --n_mels $n_mels \\\n",
    "                          --hop_length $hop_length --tile_width $tw \\\n",
    "                          --save_preds true >> log.predict\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 00vision_losses.ipynb.\n",
      "Converted 00vision_models.ipynb.\n",
      "Converted 00vision_triplet.ipynb.\n",
      "Converted 01audio_augmentations.ipynb.\n",
      "Converted 01audio_core.ipynb.\n",
      "Converted 01audio_dataset.ipynb.\n",
      "Converted 01audio_util.ipynb.\n",
      "Converted 88_external_xresnet_ssa.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted kaggle_rfcx-species-audio-detection-sed.ipynb.\n",
      "Converted kaggle_rfcx-species-audio-detection.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (banet_dev)",
   "language": "python",
   "name": "banet_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
