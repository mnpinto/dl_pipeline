{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp kaggle.rfcx_species_audio_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle rfcx-species-audio-detection competition\n",
    "\n",
    "> This module contains the pipeline for the rfcx-species-audio-detection competition: https://www.kaggle.com/c/rfcx-species-audio-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from fastprogress import progress_bar\n",
    "from IPython.core.debugger import set_trace\n",
    "import gc\n",
    "from fastscript import *\n",
    "from fastcore.all import *\n",
    "from fastai.vision.all import *\n",
    "from dl_pipeline.core import *\n",
    "from dl_pipeline.audio.core import *\n",
    "from dl_pipeline.audio.augmentations import *\n",
    "from dl_pipeline.audio.dataset import *\n",
    "from dl_pipeline.vision.models import *\n",
    "from dl_pipeline.vision.losses import *\n",
    "from dl_pipeline.audio.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample and save waveform data in npy files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will read the input flac files using librosa, resample to 32000 Hz and save as npy files. This will save time for loading the data during training and inference. If the files already exist in the path_save_npy, they will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#1992) [None,None,None,None,None,None,None,None,None,None...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate = 32_000\n",
    "path = Path('/kaggle/kaggle_rainforest_audio/data')\n",
    "train_path = path/'train'\n",
    "test_path = path/'test'\n",
    "path_save_npy = Path(path/f'npy{sample_rate}/train')\n",
    "\n",
    "files = train_path.ls()\n",
    "files = [f for f in files if '.flac' in f.suffix]\n",
    "f = partial(audio2npy, path_save=path_save_npy, sample_rate=sample_rate)\n",
    "parallel(f, files)\n",
    "\n",
    "files = test_path.ls()\n",
    "files = [f for f in files if '.flac' in f.suffix]\n",
    "f = partial(audio2npy, path_save=path_save_npy, sample_rate=sample_rate)\n",
    "parallel(f, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define agumentation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def audio_augment(sample_rate, p=0.25):\n",
    "    return Pipeline([\n",
    "        ClippingDistortion(sample_rate, max_percentile_threshold=10, p=p),\n",
    "        PitchShift(sample_rate, min_semitones=-8, max_semitones=8, p=p),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train(sample_rate, num_classes, fold, n_epochs, lr, wd, tile_width, bs, aug_ps, \n",
    "          model_name, loss_func, plot, load_checkpoint=None, lr_find=False, head_ps=0.8,\n",
    "          mixup=False, n_mels=128, hop_length=512, model_arch='resnest50'):\n",
    "    seed_everything()\n",
    "    cbs = []\n",
    "    path = Path('/kaggle/kaggle_rainforest_audio/data')\n",
    "    rename_cols = RenameColumns(id='recording_id', label='species_id', tmin='t_min', \n",
    "                                tmax='t_max',fmin='f_min', fmax='f_max')\n",
    "    \n",
    "    df = Pipeline([load_dataframe, rename_cols, group_labels])(path/'train_tp.csv')\n",
    "        \n",
    "    train_df, valid_df = kfold_dataframes(df, fold)\n",
    "        \n",
    "    tfms = partial(apply_augmentations, augs_pipeline=audio_augment(sample_rate, p=aug_ps))\n",
    "\n",
    "    train_data = Datasets(items=train_df, tfms=partial(create_dataset_item, path=path,\n",
    "                                               sample_rate=sample_rate, tile_width=tile_width,\n",
    "                                               n_mels=n_mels, hop_length=hop_length))\n",
    "    \n",
    "    valid_data = Datasets(items=valid_df, tfms=partial(create_dataset_item, path=path,\n",
    "                                               sample_rate=sample_rate, tile_width=tile_width,\n",
    "                                               n_mels=n_mels, hop_length=hop_length))\n",
    "    train_dl = DataLoader(\n",
    "        train_data, bs=bs, do_batch=reorganize_batch, shuffle=True, \n",
    "        num_workers=8, after_item=tfms, \n",
    "        after_batch=MelSpectrogram(sample_rate,n_mels=n_mels,hop_length=hop_length))\n",
    "    \n",
    "    valid_dl = DataLoader(\n",
    "        valid_data, bs=bs, do_batch=reorganize_batch, num_workers=8,\n",
    "        after_batch=MelSpectrogram(sample_rate, n_mels=n_mels,hop_length=hop_length))\n",
    "    \n",
    "    dls = DataLoaders(train_dl, valid_dl)\n",
    "    dls.device = torch.device(\"cuda:0\")        \n",
    "    \n",
    "    if plot: \n",
    "        xb, yb = dls.one_batch()\n",
    "        show_augmentations(train_data, train_dl, sample_rate=sample_rate)\n",
    "\n",
    "    model = get_model(model_arch, num_classes=num_classes, head_ps=head_ps, in_channels=1)\n",
    "    \n",
    "    if mixup: \n",
    "        cbs.append(MixUp(0.4))\n",
    "        loss_func += '_mixup'\n",
    "    \n",
    "    def before_loss(x,y):\n",
    "        x,y=mask2category(x,y)\n",
    "        return x, y\n",
    "    \n",
    "    def after_loss(loss, y):\n",
    "        return loss\n",
    "    \n",
    "    loss = get_loss(loss_func, before=before_loss, after=after_loss)\n",
    "    print('Loss function: ', loss_func)\n",
    "            \n",
    "    learn = Learner(dls, model, loss_func=loss, metrics=[accuracy, lrap], cbs=cbs)\n",
    "    learn.to_fp16(clip=0.5);\n",
    "        \n",
    "    if load_checkpoint is not None:\n",
    "        learn.load(path.parent/f'models/{load_checkpoint}_fold{fold}')\n",
    "        print('Load model ', path.parent/f'models/{load_checkpoint}_fold{fold}')\n",
    "        \n",
    "    if lr_find: learn.lr_find()\n",
    "\n",
    "    learn.fit_one_cycle(n_epochs, lr, wd=wd, div_final=10, div=10)\n",
    "    learn.save(path.parent/f'models/{model_name}_fold{fold}')\n",
    "    print(f'Model saved to', path.parent/f'models/{model_name}_fold{fold}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define inference setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def post_processing(df, path_save, model_name, tile_width, MODE=2):\n",
    "    \"\"\"\n",
    "    Post processing idea by Chris Deotte shared at \n",
    "    https://www.kaggle.com/c/rfcx-species-audio-detection/discussion/220389\n",
    "    \"\"\"\n",
    "    # USE MODE 1, 2, or 3\n",
    "    # LOAD SUBMISSION\n",
    "    FUDGE = 2.0\n",
    "    for k in range(24):\n",
    "        df.iloc[:,1+k] -= df.iloc[:,1+k].min()\n",
    "        df.iloc[:,1+k] /= df.iloc[:,1+k].max()\n",
    "\n",
    "    # CONVERT PROBS TO ODDS, APPLY MULTIPLIER, CONVERT BACK TO PROBS\n",
    "    def scale(probs, factor):\n",
    "        probs = probs.copy()\n",
    "        idx = np.where(probs!=1)[0]\n",
    "        odds = factor * probs[idx] / (1-probs[idx])\n",
    "        probs[idx] =  odds/(1+odds)\n",
    "        return probs\n",
    "\n",
    "    # TRAIN AND TEST MEANS\n",
    "    d1 = df.iloc[:,1:].mean().values\n",
    "    d2 = np.array([113,204,44,923,53,41,3,213,44,23,26,149,255,14,123,222,46,6,474,4,17,18,23,72])/1000.\n",
    "\n",
    "    for k in range(24):\n",
    "        if MODE==1: d = FUDGE\n",
    "        if MODE==2: d = d1[k]/(1-d1[k])\n",
    "        if MODE==3: s = d2[k] / d1[k]\n",
    "        else: s = (d2[k]/(1-d2[k]))/d\n",
    "        df.iloc[:,k+1] = scale(df.iloc[:,k+1].values,s)\n",
    "\n",
    "    df.to_csv(path_save/f'submission_with_pp_{model_name}_{tile_width}.csv',index=False)\n",
    "    \n",
    "def ensemble(files):\n",
    "    dfs = [pd.read_csv(f) for f in files]\n",
    "    df = pd.concat(dfs).groupby('recording_id').mean().reset_index()\n",
    "    tstr = datetime.now().strftime('%Y%m%d%H%M')\n",
    "    fsave = files[0].parent/f'submission_ens_{tstr}.csv'\n",
    "    df.to_csv(fsave, index=False)\n",
    "    print(f'Saved to {fsave}')\n",
    "    \n",
    "def get_preds(dataloader, model, device=torch.device(\"cuda:0\"), max_reduce=True):\n",
    "    model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "        preds, ys = [], []\n",
    "        for x, y in progress_bar(dataloader):\n",
    "            if max_reduce:\n",
    "                pred = model(x).max(0).values[None]\n",
    "            else:\n",
    "                pred = model(x)[None]\n",
    "            preds.append(pred.cpu())\n",
    "            ys.append(y.cpu())\n",
    "        preds = torch.cat(preds, dim=0)\n",
    "        ys = torch.cat(ys, dim=0)\n",
    "    return preds, ys\n",
    "        \n",
    "def test(sample_rate, num_classes, tile_widths, model_name, ens_folds, head_ps=0.8, \n",
    "         n_mels=128, hop_length=512, save_preds=False, model_arch='resnest50'):\n",
    "    bs = 1\n",
    "    _path_save = Path('preds')\n",
    "    _path_save.mkdir(exist_ok=True)\n",
    "    max_reduce = not save_preds\n",
    "\n",
    "    ens_files = []\n",
    "    for tile_width in tile_widths:\n",
    "        print(f'Running inference for tile_width {tile_width}')\n",
    "        preds_ens, preds_valid, ys_valid = [], [], []\n",
    "        preds_train, ys_train = [], []\n",
    "        for fold in ens_folds:\n",
    "            seed_everything()\n",
    "            print(f'Running inference for fold {fold}')\n",
    "            path = Path('/kaggle/kaggle_rainforest_audio/data')\n",
    "            rename_cols_test = RenameColumns(id='recording_id')\n",
    "            rename_cols_valid = RenameColumns(id='recording_id', label='species_id', tmin='t_min', \n",
    "                                        tmax='t_max',fmin='f_min', fmax='f_max')\n",
    "\n",
    "            df = Pipeline([load_dataframe, rename_cols_valid, group_labels])(path/'train_tp.csv')\n",
    "\n",
    "            train_df, valid_df = kfold_dataframes(df, fold)\n",
    "\n",
    "            test_df = Pipeline([load_dataframe, rename_cols_test])(path/'sample_submission.csv')\n",
    "            fp_df = Pipeline([load_dataframe, rename_cols_valid, group_labels])(path/'train_fp.csv')\n",
    "\n",
    "            datasets = [Datasets(items=dataframe, tfms=partial(create_dataset_item, path=path,\n",
    "                sample_rate=sample_rate, tile_width=None, n_mels=n_mels, hop_length=hop_length))\n",
    "                for dataframe in [train_df, valid_df, test_df, fp_df]]\n",
    "\n",
    "            dls = DataLoaders(*[DataLoader(dataset, bs=bs, do_batch=reorganize_batch, num_workers=8, \n",
    "                            after_batch=Pipeline([MelSpectrogram(sample_rate, n_mels=n_mels, \n",
    "                                        hop_length=hop_length), TilesTransform(tile_width)])) \n",
    "                 for dataset in datasets])\n",
    "\n",
    "            model = get_model(model_arch, num_classes=num_classes, head_ps=head_ps, in_channels=1,\n",
    "                              pretrained=False)\n",
    "\n",
    "            dls.device = torch.device(\"cuda:0\")        \n",
    "            learn = Learner(dls, model, loss_func=cross_entropy, metrics=[accuracy, lrap])\n",
    "            learn.to_fp16(clip=0.5);\n",
    "            learn.load(path.parent/f'models/{model_name}_fold{fold}')\n",
    "            print('Load model: ', path.parent/f'models/{model_name}_fold{fold}')\n",
    "\n",
    "            preds, ys = get_preds(dls[1], model, max_reduce=max_reduce)\n",
    "            np.save(_path_save/f'{model_name}_{tile_width}_fold{fold}_valid.npy', \n",
    "                    {'preds':preds, 'ys':ys})\n",
    "            if not max_reduce: preds = preds.max(1).values\n",
    "            preds_valid.append(preds)\n",
    "            ys_valid.append(ys)\n",
    "\n",
    "            preds, ys = get_preds(dls[2], model, max_reduce=max_reduce)\n",
    "            np.save(_path_save/f'{model_name}_{tile_width}_fold{fold}_test.npy', \n",
    "                    {'preds':preds, 'ys':ys})\n",
    "            if not max_reduce: preds = preds.max(1).values\n",
    "            preds_ens.append(preds[None])\n",
    "\n",
    "        preds_valid, ys_valid = torch.cat(preds_valid), torch.cat(ys_valid)\n",
    "        valid_score = lrap(preds_valid, ys_valid.long().squeeze(), before=lambda *o:o)\n",
    "        print(f'Validation score: {valid_score:.3f}')\n",
    "\n",
    "        preds_ens = torch.cat(preds_ens).mean(0).softmax(-1)\n",
    "        test_df = Pipeline([load_dataframe])(path/'sample_submission.csv')\n",
    "\n",
    "        for i in range(preds_ens.shape[1]):\n",
    "            test_df.loc[:, f's{i}'] = preds_ens[:,i]\n",
    "\n",
    "        tstr = datetime.now().strftime('%Y%m%d%H%M')\n",
    "        test_df.to_csv(path.parent/f'subs/submission_{tstr}.csv',index=False)\n",
    "        print('Submission file saved: ', path.parent/f'subs/submission_{model_name}_{tile_width}.csv')\n",
    "        \n",
    "        #Post-processing\n",
    "        post_processing(test_df, path.parent/'subs', model_name, tile_width)\n",
    "        \n",
    "        ens_files.append(path.parent/f'subs/submission_with_pp_{model_name}_{tile_width}.csv')\n",
    "    ensemble(ens_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create command line function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def main(fold:Param('Fold number', int)=0, \n",
    "         n_epochs:Param('Number of training epochs', int)=30,\n",
    "         lr:Param('Learning rate', float)=1e-3,\n",
    "         wd:Param('Weight decay', float)=3e-2,\n",
    "         loss_func:Param('Loss function', str)='cross_entropy',\n",
    "         tile_width:Param('Tile width', int)=1024,\n",
    "         tile_widths_inference:Param('List of tile widths for inference', list)=[128,256],\n",
    "         sample_rate:Param('Sample rate', int)=32000,\n",
    "         n_mels:Param('Spectrogram n_mels', int)=128,\n",
    "         hop_length:Param('Spectrogram hop_length', int)=640,\n",
    "         bs:Param('Batch size', int)=32,\n",
    "         accumulate_gradients:Param('Batch size for gradient accumulation', int)=None,\n",
    "         aug_ps:Param('Augmentation probability', float)=0.25,\n",
    "         model_arch:Param('Name of model architecture', str)='densenet121',\n",
    "         model_name:Param('Name of parameters file', str)='model_n0',\n",
    "         ens_folds:Param('Folds to use for ensemble', list)=[0,1,2,3,4],\n",
    "         run_test:Param('Run test prediction (default is train)', str)=False,\n",
    "         load_checkpoint:Param('Load model checkpoint before new train loop', str)=None,\n",
    "         head_ps:Param('Model head dropout probability', float)=0.8,\n",
    "         mixup:Param('Use mixup', str)=True,\n",
    "         save_preds:Param('Save model predictions for train and validation', str)=False):\n",
    "    \n",
    "    num_classes = 24\n",
    "    if run_test in [True, 'true', 'True']: run_test = True\n",
    "    if mixup in [True, 'true', 'True']: mixup = True\n",
    "    if save_preds in [True, 'true', 'True']: save_preds=True\n",
    "    if run_test:\n",
    "        test(sample_rate, num_classes, tile_widths_inference, model_name, ens_folds, head_ps=head_ps, \n",
    "             n_mels=n_mels, hop_length=hop_length, save_preds=save_preds, model_arch=model_arch)\n",
    "    else:\n",
    "        train(sample_rate, num_classes, fold, n_epochs, lr, wd, tile_width, bs, aug_ps, \n",
    "          model_name, loss_func, plot=False, load_checkpoint=load_checkpoint, lr_find=False,\n",
    "          head_ps=head_ps, mixup=mixup, n_mels=n_mels, hop_length=hop_length, model_arch=model_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Train model\n",
    "```python\n",
    "for i in [0,1,2,3,4]:\n",
    "    train(\n",
    "        sample_rate=32000,\n",
    "        num_classes=24,\n",
    "        fold=i,\n",
    "        n_epochs=30,\n",
    "        lr=1e-3,\n",
    "        wd=3e-2,\n",
    "        n_mels=128,\n",
    "        hop_length=640,\n",
    "        tile_width=1024,\n",
    "        bs=32,\n",
    "        aug_ps=0.25,\n",
    "        model_arch='resnest50',\n",
    "        model_name='model_n100',\n",
    "        loss_func='cross_entropy', \n",
    "        plot=False,  \n",
    "        load_checkpoint=None, \n",
    "        lr_find=False, \n",
    "        head_ps=0.8,\n",
    "        mixup=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions for test data\n",
    "```python\n",
    "test(sample_rate=32000, \n",
    "     num_classes=24, \n",
    "     n_mels=128,\n",
    "     hop_length=640,\n",
    "     tile_width=[128,256], \n",
    "     model_arch='resnest50',\n",
    "     model_name='model_n100', \n",
    "     ens_folds=[0,1,2,3,4],\n",
    "     save_preds=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running train and predictions on terminal\n",
    "```bash\n",
    "#!/bin/bash\n",
    "arch='resnest50'\n",
    "model_name='model_n100'\n",
    "sample_rate=32000\n",
    "n_mels=128\n",
    "hop_length=640\n",
    "for fold in 0 1 2 3 4\n",
    "do\n",
    "    echo \"Training $model for fold $fold\"\n",
    "    kaggle_rainforest2021 --fold $fold --model_name $model_name --model_arch $arch \\\n",
    "                          --sample_rate $sample_rate --n_mels $n_mels \\\n",
    "                          --hop_length $hop_length --bs 32 --head_ps 0.8 \\\n",
    "                          --tile_width 1024 --mixup true >> log.train\n",
    "done\n",
    "\n",
    "echo \"Generate predictions for $model\"\n",
    "kaggle_rainforest2021 --run_test true --model_name $model_name --model_arch $arch \\\n",
    "                      --sample_rate $sample_rate --n_mels $n_mels \\\n",
    "                      --hop_length $hop_length --save_preds true >> log.predict\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 00vision_losses.ipynb.\n",
      "Converted 00vision_models.ipynb.\n",
      "Converted 00vision_triplet.ipynb.\n",
      "Converted 01audio_augmentations.ipynb.\n",
      "Converted 01audio_core.ipynb.\n",
      "Converted 01audio_dataset.ipynb.\n",
      "Converted 01audio_util.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted kaggle_rfcx-species-audio-detection.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (banet_dev)",
   "language": "python",
   "name": "banet_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
