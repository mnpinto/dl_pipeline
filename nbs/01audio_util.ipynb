{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp audio.util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Utility Functions \n",
    "> Includes metrics, losses and other utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Beta\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.core.debugger import set_trace\n",
    "from fastai.vision.all import *\n",
    "from dl_pipeline.audio.core import *\n",
    "from dl_pipeline.vision.losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mask2category(x, y):\n",
    "    y = TensorAudioLabel(np.nanmax(y.cpu(), axis=(1,2))).type(x.type()).to(x.device)\n",
    "    return x.float(), y.long()\n",
    "\n",
    "def accuracy(x, y, before=mask2category, after=lambda o:o):\n",
    "    f = lambda x,y : (x.argmax(-1) == y).float().mean()\n",
    "    return after(f(*before(x,y))) \n",
    "\n",
    "def lrap(x, y, before=mask2category, after=lambda o:o):\n",
    "    x, y = before(x, y)\n",
    "    y = F.one_hot(y, x.shape[1]).cpu().numpy()\n",
    "    x = x.softmax(1).cpu().numpy()\n",
    "    return label_ranking_average_precision_score(y, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def kfold_dataframes(df, fold_number, n_splits=5, shuffle=True, random_state=2021):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "    train_idx, valid_idx = list(kf.split(df.index))[fold_number]\n",
    "    return df.loc[train_idx].reset_index(drop=True), df.loc[valid_idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.23 ms, sys: 0 ns, total: 6.23 ms\n",
      "Wall time: 6.01 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(972, 244)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('/kaggle/kaggle_rainforest_audio/data/train_tp.csv')\n",
    "train_df, valid_df = kfold_dataframes(df, 0)\n",
    "len(train_df), len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OneHot(Callback):\n",
    "    run_valid = False\n",
    "    \n",
    "    def before_batch(self):\n",
    "        self.learn.yb = tuple([F.one_hot(self.yb[0], self.dls.c).float()])\n",
    "        \n",
    "class MixUp(Callback):\n",
    "    run_valid = False\n",
    "    def __init__(self, alpha=0.4, onehot=False):\n",
    "        self.alpha = alpha\n",
    "        self.distrib = Beta(alpha, alpha)\n",
    "        self.onehot = onehot\n",
    "    \n",
    "    def before_batch(self):\n",
    "        bs      = self.xb[0].shape[0]\n",
    "        device  = self.xb[0].device\n",
    "        lambd = self.distrib.sample((self.y.size(0),)).squeeze().to(self.x.device)\n",
    "        lambd = torch.stack([lambd, 1-lambd], 1).max(1)[0]\n",
    "        shuffle = torch.randperm(bs).to(device)\n",
    "        xb1, yb1 = self.xb[0][shuffle], self.yb[0][shuffle]\n",
    "        a = tensor(lambd).float().view(-1, 1, 1, 1).to(device)\n",
    "        self.learn.xb = tuple([a*self.xb[0] + (1-a)*xb1])\n",
    "        a = a.view(-1)\n",
    "        if self.onehot:\n",
    "            while len(a.shape) < len(yb1.shape):\n",
    "                a = a[...,None]\n",
    "            self.learn.yb = tuple([a*self.learn.yb[0] + (1-a)*yb1])\n",
    "        else:\n",
    "            self.learn.yb = tuple([{'yb': self.learn.yb[0], 'yb1': yb1, 'a': a}])\n",
    "            \n",
    "class LabelSED(Callback):\n",
    "    run_valid = True\n",
    "    def __init__(self, model_n_rescales):\n",
    "        self.rescale = 2**model_n_rescales\n",
    "        \n",
    "    def before_batch(self):\n",
    "        y = self.learn.yb[0]\n",
    "        y = y[...,::y.shape[-1]//self.rescale].max(2).values.float()\n",
    "        self.learn.yb = tuple([y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 214 µs, sys: 29 µs, total: 243 µs\n",
      "Wall time: 219 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MixUp"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "MixUp(0.4, onehot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 00vision_losses.ipynb.\n",
      "Converted 00vision_models.ipynb.\n",
      "Converted 00vision_triplet.ipynb.\n",
      "Converted 01audio_augmentations.ipynb.\n",
      "Converted 01audio_core.ipynb.\n",
      "Converted 01audio_dataset.ipynb.\n",
      "Converted 01audio_util.ipynb.\n",
      "Converted 88_external_xresnet_ssa.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted kaggle_rfcx-species-audio-detection-sed.ipynb.\n",
      "Converted kaggle_rfcx-species-audio-detection.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide \n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (banet_dev)",
   "language": "python",
   "name": "banet_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
