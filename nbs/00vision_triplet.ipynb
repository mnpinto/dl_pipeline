{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp vision.triplet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Learning\n",
    "> Functions for triplet learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision.all import *\n",
    "from torch.utils.data import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SampleEpisode(Sampler):\n",
    "    def __init__(self, ys, n_episodes, n_way, k_shot, hard_samples=True, \n",
    "                 distance_matrix=None):\n",
    "        self.epoch_size = n_episodes\n",
    "        self.n_way, self.k_shot = n_way, k_shot\n",
    "        self.ids = ys\n",
    "        self.classes = np.array(list(set(self.ids)))\n",
    "        self.hard_samples = hard_samples\n",
    "        self.distance_matrix = distance_matrix\n",
    "        self._epochs = []\n",
    "        \n",
    "    def __len__(self): \n",
    "        return self.epoch_size*self.n_way*self.k_shot\n",
    "        \n",
    "    def __iter__(self): return iter(self.get_epoch())\n",
    "    \n",
    "    def get_epoch(self):\n",
    "        \"\"\"Get indices for one epoch of size epoch_size\"\"\"\n",
    "        idx = []\n",
    "        for n in range(self.epoch_size):\n",
    "            idx = [*idx, *self.get_batch()]\n",
    "        return idx\n",
    "    \n",
    "    def get_batch(self):\n",
    "        \"\"\"Get indices for one mini-batch\"\"\"\n",
    "        idx = []\n",
    "        hard_samples = self.hard_samples if self.distance_matrix is not None else False\n",
    "        try:\n",
    "            support_classes = np.random.choice(self.classes, size=self.n_way, replace=False)\n",
    "        except:       \n",
    "            support_classes = np.random.choice(self.classes, size=self.n_way, replace=True)\n",
    "        for k in support_classes:\n",
    "            if hard_samples:\n",
    "                s = self.get_hard_samples(k, idx)\n",
    "                idx = [*idx[:-1], *s]\n",
    "            else:\n",
    "                s = self.random_sample(k)\n",
    "                idx = [*idx, *s]\n",
    "        if hard_samples: idx = idx[:-1]       \n",
    "        return idx\n",
    "            \n",
    "    def random_sample(self, k):\n",
    "        \"\"\"Random samples are n-way k-shot\"\"\"\n",
    "        idx = []\n",
    "        where = np.where(self.ids==k)[0]\n",
    "        available = len(where)\n",
    "        replace = True if available < self.k_shot else False\n",
    "        if replace:\n",
    "            idx.append(np.random.choice(where, size=available, replace=False))\n",
    "            idx.append(np.random.choice(where, size=self.k_shot-available, replace=True))\n",
    "        else:\n",
    "            idx.append(np.random.choice(where, size=self.k_shot, replace=False))\n",
    "        return np.concatenate(idx)\n",
    "    \n",
    "    def get_hard_samples(self, k, idx=None):\n",
    "        \"\"\"\n",
    "        Hard samples are selected as the positives with higher distance and \n",
    "        negatives with smaller distance from the anchor image\n",
    "        \"\"\"\n",
    "        dists = self.distance_matrix\n",
    "        if len(idx) == 0:\n",
    "            where = np.where(self.ids==k)[0]\n",
    "            anchor_idx = np.random.choice(where, size=1, replace=False)\n",
    "        else: \n",
    "            anchor_idx = np.array([idx[-1]])\n",
    "            k = self.ids[self.ids==self.ids[anchor_idx]][0]\n",
    "            where = np.where(self.ids==k)[0]\n",
    "            \n",
    "        if len(where) > self.k_shot-1:\n",
    "            hardest_positives = np.array(where[dists[anchor_idx, where]\n",
    "                                 .sort(descending=True)[1][:self.k_shot-1]])\n",
    "        else: \n",
    "            hardest_positives = [*where,\n",
    "                *np.random.choice(where, size=self.k_shot-len(where)-1, replace=True)]\n",
    "        ids_in_idx = np.zeros((len(self.ids)))\n",
    "        if len(idx) != 0:\n",
    "            classes_in_idx = np.array(list(set(self.ids[idx])))\n",
    "            for c in classes_in_idx: ids_in_idx[self.ids==c] = 1\n",
    "        where = np.where((self.ids!=k) & (ids_in_idx==0))[0]\n",
    "        if len(where)==0: where = np.where(self.ids!=k)[0]\n",
    "        hardest_negative = np.array([where[dists[anchor_idx, where].sort().indices[0]]])\n",
    "        return [*anchor_idx, *hardest_positives, *hardest_negative]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compute_distance_matrix(dataloader, model=None):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        embs = []\n",
    "        t = children_and_parameters(model)[0][0][0].weight.data.type()\n",
    "        for xb, yb in dataloader:\n",
    "            emb = model(xb.type(t)).float()\n",
    "            embs.append(emb)\n",
    "        embs = torch.cat(embs, dim=0)\n",
    "        dmat = []\n",
    "        for e in embs:\n",
    "            s = (e.view(1,-1) - embs).pow_(2).sum(1).pow_(0.5).unsqueeze(1)\n",
    "            dmat.append(s)\n",
    "        dmat = torch.cat(dmat, dim=1).cpu()\n",
    "        model.train()\n",
    "        gc.collect()\n",
    "        return dmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EpisodeDataLoader(DataLoader):\n",
    "    _sampler = SampleEpisode\n",
    "    def __init__(self, fix_dl, dataset=None, model=None, n_episodes=100, n_way=16, k_shot=4, **kwargs):\n",
    "        super().__init__(dataset=dataset, **kwargs)\n",
    "        self.fix_dl = fix_dl\n",
    "        self.n_way, self.k_shot = n_way, k_shot\n",
    "        ys = np.array([int(np.nanmax(o[0][1].cpu())) for o in self.fix_dl.dataset])\n",
    "        self.sampler = self._sampler(ys, n_episodes, n_way, k_shot)\n",
    "        self.model = model\n",
    "        self.n_episodes = n_episodes\n",
    "        \n",
    "    def before_iter(self):\n",
    "        self.sampler.distance_matrix = compute_distance_matrix(self.fix_dl, self.model)\n",
    "        \n",
    "    def get_idxs(self):\n",
    "        return list(self.sampler.__iter__())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_episodes\n",
    "    \n",
    "    def create_item(self, s):  \n",
    "        try:o = next(self.it) if s is None else self.dataset[s]\n",
    "        except:set_trace()\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_preds(dataloader=None, model=None):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        preds, ys = [], []\n",
    "        t = children_and_parameters(model)[0][0][0].weight.data.type()\n",
    "        for xb, yb in dataloader:\n",
    "            xb, yb = mask2category(xb,yb)\n",
    "            p = model(xb.type(t)).float()\n",
    "            preds.append(p)\n",
    "            ys.append(yb)\n",
    "        preds = torch.cat(preds, dim=0)\n",
    "        ys = torch.cat(ys, dim=0)\n",
    "        model.train()\n",
    "        gc.collect()\n",
    "        return preds, ys\n",
    "        \n",
    "def distance(valid_preds, train_preds, train_ys, n=100):\n",
    "    \"\"\"Compute distance of each valid sample to the train samples\"\"\"\n",
    "    classes_preds, dists = [], []\n",
    "    for x in valid_preds:\n",
    "        d = (x.view(1,-1) - train_preds).pow(2).sum(-1).pow(0.5).sort()\n",
    "        classes_preds.append(train_ys[d[1][:n]].view(1,-1))\n",
    "        dists.append(d[0][:n].view(1,-1))\n",
    "    classes_preds = torch.cat(classes_preds, dim=0)\n",
    "    dists = torch.cat(dists, dim=0)\n",
    "    return classes_preds, dists\n",
    "    \n",
    "def remove_duplicates(classes_preds, n=5):\n",
    "    final_classes = []\n",
    "    for cl in classes_preds:\n",
    "        g = []\n",
    "        for c in cl:\n",
    "            if len(g) < n and c not in g:\n",
    "                g.append(c.item())\n",
    "        final_classes.append(g) \n",
    "    return torch.tensor(final_classes)\n",
    "\n",
    "def map5(final_classes, valid_y):\n",
    "    out = 0\n",
    "    for i in range(5):\n",
    "        out+=(final_classes[:, i] == valid_y).float().mean().item()*(1/(i+1))\n",
    "    return out\n",
    "\n",
    "def accuracy(x, y, dls=None, model=None, fix_dl_train_idx=2, fix_dl_valid_idx=3):\n",
    "    train_preds, train_ys = get_preds(dls[fix_dl_train_idx], model)\n",
    "    valid_preds, valid_ys = get_preds(dls[fix_dl_valid_idx], model)\n",
    "    classes_preds, dists = distance(valid_preds, train_preds, train_ys)\n",
    "    final_classes = classes_preds#remove_duplicates(classes_preds)\n",
    "    accuracy = (final_classes[:, 0] == valid_ys).float().mean().cpu().item()\n",
    "    return torch.FloatTensor([accuracy])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#todo\n",
    "fold=0\n",
    "sample_rate=32000\n",
    "aug_ps=0.25\n",
    "tile_width=256\n",
    "bs=64\n",
    "seed_everything()\n",
    "cbs = []\n",
    "path = Path('/kaggle/kaggle_rainforest_audio/data')\n",
    "\n",
    "rename_cols = RenameColumns(id='recording_id', label='species_id', tmin='t_min', \n",
    "                            tmax='t_max',fmin='f_min', fmax='f_max')\n",
    "df = Pipeline([load_dataframe, rename_cols, group_labels])(path/'train_tp.csv')\n",
    "train_df, valid_df = kfold_dataframes(df, fold)\n",
    "\n",
    "model = EmbResNeSt50().cuda()\n",
    "st = torch.load('/kaggle/kaggle_rainforest_audio/models/model_n0_fold0.pth')['model']\n",
    "del st['layers.14.weight'], st['layers.14.bias']\n",
    "\n",
    "tfms = partial(apply_augmentations, augs_pipeline=audio_augment(sample_rate, p=aug_ps))\n",
    "#tfms = None\n",
    "\n",
    "train_data = Datasets(items=train_df, tfms=partial(create_dataset_item, path=path,\n",
    "                                           sample_rate=sample_rate, tile_width=tile_width))\n",
    "valid_data = Datasets(items=valid_df, tfms=partial(create_dataset_item, path=path,\n",
    "                                           sample_rate=sample_rate, tile_width=tile_width))\n",
    "fix_dl_train   = DataLoader(train_data, bs=bs, do_batch=reorganize_batch, num_workers=8,\n",
    "                      after_batch=MelSpectrogram(sample_rate))\n",
    "train_dl = EpisodeDataLoader(fix_dl_train, n_episodes=100, dataset=train_data, model=model, bs=bs, do_batch=reorganize_batch, shuffle=True, num_workers=8,\n",
    "                      after_item=tfms, after_batch=MelSpectrogram(sample_rate))\n",
    "fix_dl_valid = DataLoader(valid_data, bs=bs, do_batch=reorganize_batch, num_workers=8,\n",
    "                          after_batch=MelSpectrogram(sample_rate))\n",
    "valid_dl = EpisodeDataLoader(fix_dl_valid, n_episodes=1, dataset=valid_data, model=model, bs=bs, do_batch=reorganize_batch, num_workers=8,\n",
    "                          after_batch=MelSpectrogram(sample_rate))\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl, fix_dl_train, fix_dl_valid)\n",
    "dls.device = torch.device(\"cuda:0\")        \n",
    "\n",
    "#xb, yb = dls.one_batch()\n",
    "#show_augmentations(train_data, train_dl, sample_rate=sample_rate)\n",
    "\n",
    "loss_func = 'soft_triplet_loss'\n",
    "if loss_func == 'soft_triplet_loss':\n",
    "    loss = SoftTripletLoss(4)\n",
    "\n",
    "print('Loss function: ', loss_func)\n",
    "metric = partial(accuracy, dls=dls, model=model)\n",
    "learn = Learner(dls, model, loss_func=loss, metrics=metric, cbs=cbs)\n",
    "learn.to_fp16(clip=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 00vision_models.ipynb.\n",
      "Converted 00vision_triplet.ipynb.\n",
      "Converted 01audio_augmentations.ipynb.\n",
      "Converted 01audio_core.ipynb.\n",
      "Converted 01audio_dataset.ipynb.\n",
      "Converted 01audio_util.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted kaggle_rfcx-species-audio-detection.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (banet_dev)",
   "language": "python",
   "name": "banet_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
